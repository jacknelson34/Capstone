{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7WtZW-u-WLpW",
        "outputId": "da0171b5-aeb9-4751-b1a4-a44a40f2b820"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the large PNG image\n",
        "image = cv2.imread('/content/143HD_003.png')\n",
        "\n",
        "# Resize the image to 25% of its original size\n",
        "resized_image = cv2.resize(image, (0, 0), fx=0.25, fy=0.25)\n",
        "\n",
        "# Save the resized image\n",
        "cv2.imwrite('resized_image.png', resized_image)\n",
        "\n",
        "# Verify the resize by displaying\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c9u2szxoUldo",
        "outputId": "5e1f5ad8-ffe8-4154-c0d7-369dc02d1814"
      },
      "outputs": [],
      "source": [
        "def adaptive_brightness_contrast(image):\n",
        "    \"\"\"\n",
        "    Adjust brightness and contrast adaptively using histogram equalization.\n",
        "    \"\"\"\n",
        "    # Convert to YUV color space\n",
        "    yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
        "    # Equalize the histogram of the Y channel\n",
        "    yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])\n",
        "    # Convert back to BGR color space\n",
        "    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
        "\n",
        "def remove_white_space(image):\n",
        "    \"\"\"\n",
        "    Remove white space from an image by cropping to the bounding box of non-white areas.\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Invert the image so white becomes black and vice versa\n",
        "    inverted = cv2.bitwise_not(gray)\n",
        "\n",
        "    # Threshold to create a binary image\n",
        "    _, thresh = cv2.threshold(inverted, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours of the non-white areas\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if contours:\n",
        "        # Get bounding box for the non-white regions\n",
        "        x, y, w, h = cv2.boundingRect(np.concatenate(contours))\n",
        "\n",
        "        # Crop the image to the bounding box\n",
        "        cropped_image = image[y:y+h, x:x+w]\n",
        "        return cropped_image\n",
        "    return image  # Return original if no white space is detected\n",
        "\n",
        "def dynamic_canny(image):\n",
        "    \"\"\"\n",
        "    Perform edge detection using dynamic thresholds based on the image's median intensity.\n",
        "    \"\"\"\n",
        "    median_val = np.median(image)\n",
        "    lower = int(max(0, 0.7 * median_val))\n",
        "    upper = int(min(255, 1.3 * median_val))\n",
        "    return cv2.Canny(image, lower, upper)\n",
        "\n",
        "def process_subimage(subimage):\n",
        "    \"\"\"\n",
        "    Process a subimage to detect ROIs, balancing edge detection and low-contrast thresholding.\n",
        "    \"\"\"\n",
        "    # Step 1: Adjust brightness and contrast adaptively\n",
        "    adjusted_image = adaptive_brightness_contrast(subimage)\n",
        "\n",
        "    # Step 2: Remove white space\n",
        "    cropped_image = remove_white_space(adjusted_image)\n",
        "\n",
        "    # Step 3: Convert to grayscale\n",
        "    gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Step 4: Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Step 5: Use dynamic Canny edge detection to find edges\n",
        "    edges = dynamic_canny(blurred)\n",
        "\n",
        "    # Step 6: Slightly dilate edges to connect close features\n",
        "    kernel = np.ones((3, 3), np.uint8)  # Smaller kernel for precision\n",
        "    edges_dilated = cv2.dilate(edges, kernel, iterations=1)\n",
        "\n",
        "    # Step 7: Apply threshold to enhance low-contrast areas\n",
        "    _, thresholded = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Step 8: Combine edges and thresholded areas, with priority on edges\n",
        "    combined = cv2.bitwise_or(edges_dilated, cv2.bitwise_and(thresholded, edges))\n",
        "\n",
        "    # Step 9: Find contours from the combined image\n",
        "    contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    rois = []\n",
        "    for contour in contours:\n",
        "        # Get bounding box for each contour\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        x_midpoint = x + w / 2\n",
        "        y_midpoint = y + h / 2\n",
        "\n",
        "        # Ignore very small contours (noise)\n",
        "        if w > 5 and h > 5:  # Filter small boxes\n",
        "            roi = {\n",
        "                \"x_midpoint\": x_midpoint,\n",
        "                \"y_midpoint\": y_midpoint,\n",
        "                \"x_length\": w,\n",
        "                \"y_length\": h,\n",
        "            }\n",
        "            rois.append(roi)\n",
        "\n",
        "            # Draw bounding box for visualization\n",
        "            cv2.rectangle(cropped_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # Display the cropped image with bounding boxes\n",
        "    cv2_imshow(cropped_image)\n",
        "\n",
        "    return rois, cropped_image\n",
        "\n",
        "\n",
        "def divide_image_into_grid_with_overlap(image, grid_size, overlap=0.1):\n",
        "    \"\"\"\n",
        "    Divide the image into a grid with overlapping regions between subimages.\n",
        "    \"\"\"\n",
        "    image_height, image_width = image.shape[:2]\n",
        "    rows, cols = grid_size\n",
        "    sub_height = image_height // rows\n",
        "    sub_width = image_width // cols\n",
        "    overlap_h = int(overlap * sub_height)\n",
        "    overlap_w = int(overlap * sub_width)\n",
        "\n",
        "    subimages = []\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            # Calculate subimage coordinates with overlap\n",
        "            x_start = max(0, col * sub_width - overlap_w)\n",
        "            y_start = max(0, row * sub_height - overlap_h)\n",
        "            x_end = min(image_width, x_start + sub_width + 2 * overlap_w)\n",
        "            y_end = min(image_height, y_start + sub_height + 2 * overlap_h)\n",
        "\n",
        "            subimage = image[y_start:y_end, x_start:x_end]\n",
        "            subimages.append((subimage, x_start, y_start))\n",
        "\n",
        "    return subimages\n",
        "\n",
        "def process_image_with_grid(resized_image, grid_size, overlap=0.1):\n",
        "    \"\"\"\n",
        "    Divide an image into a grid with overlap and process each subimage for ROIs.\n",
        "    \"\"\"\n",
        "    image_height, image_width = resized_image.shape[:2]\n",
        "    subimages = divide_image_into_grid_with_overlap(resized_image, grid_size, overlap)\n",
        "    all_rois = []\n",
        "\n",
        "    for subimage, x_offset, y_offset in subimages:\n",
        "        # Process the subimage\n",
        "        rois, processed_subimage = process_subimage(subimage)\n",
        "\n",
        "        # Normalize ROIs to the original image\n",
        "        for roi in rois:\n",
        "            adjusted_roi = {\n",
        "                \"x_midpoint_normalized\": round((roi[\"x_midpoint\"] + x_offset) / image_width, 6),\n",
        "                \"y_midpoint_normalized\": round((roi[\"y_midpoint\"] + y_offset) / image_height, 6),\n",
        "                \"x_length_normalized\": round(roi[\"x_length\"] / image_width, 6),\n",
        "                \"y_length_normalized\": round(roi[\"y_length\"] / image_height, 6),\n",
        "            }\n",
        "            all_rois.append(adjusted_roi)\n",
        "\n",
        "    return all_rois\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/resized_image.png'  # Replace with the uploaded image path\n",
        "resized_image = cv2.imread(image_path)\n",
        "\n",
        "# Validate image loading\n",
        "if resized_image is not None:\n",
        "    image_height, image_width = resized_image.shape[:2]\n",
        "    grid_size = (image_height // 200, image_width // 200)  # Example grid size, made flexible\n",
        "    overlap = 0.1  # 10% overlap between subimages\n",
        "    rois = process_image_with_grid(resized_image, grid_size, overlap)\n",
        "    print(\"Detected ROIs:\")\n",
        "    for i, roi in enumerate(rois):\n",
        "        print(f\"ROI {i + 1}: {roi}\")\n",
        "else:\n",
        "    print(\"Error: Image could not be loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxl9BlbFZD_s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}